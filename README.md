# SynerNet
Accurately classifying radar-communication signals remains a fundamental yet challenging task, as these waveforms often exhibit high variability and are easily distorted by noise, channel fading, and spectrum overlap. Conventional deep learning approaches, despite their remarkable progress, tend to capture either local spatial cues or long-range dependencies in isolation, thereby limiting their ability to achieve robust recognition in complex environments. To address these challenges, we propose SynerNet, a lightweight deep neural architecture that effectively integrates spatial diversity and cross-scale attention mechanisms. Specifically, SynerNet leverages the smoothed pseudo Wigner-Ville distribution to generate informative time-frequency representations, which retain high resolution while mitigating undesired cross-term interference. Building upon these representations, the network is enhanced by two key components: the Gated Spatial-Channel Unit module, which jointly models spatial and channel dependencies to selectively emphasize salient features while suppressing noise, and the Fractal Cross-Scale Attention module, which employs a hierarchical fractal-inspired attention scheme to preserve fine-grained details across multiple scales while ensuring global consistency. Simulation results on 12 waveform classes encompassing both radar and communication signals demonstrate that SynerNet achieves an average classification accuracy of 90.61\%, with only 47K parameters and an inference latency of 0.552 ms, outperforming existing deep learning approaches. These results highlight the strong potential of SynerNet for real-world deployment in intelligent sensing and wireless communication systems under resource-constrained environments.


The dataset can be download on [Google Drive](https://drive.google.com/drive/u/1/folders/14DWPcBVMQ7CrNo13gEoDppv6Rn0Ze0c3) (please report if not available).

 If there is any error or need to be discussed, please email to [Thanh-Dat Tran](https://github.com/DatChanThanh) via [trandatt21@gmail.com](mailto:trandatt21@gmail.com).
